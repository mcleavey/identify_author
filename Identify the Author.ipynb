{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of classifying the speaker based on text patterns.  I first train a language model from scratch, \n",
    "and then use this to create a text classifier.  I train this classifier on novels from 5 different authors. I then present the\n",
    "model with 6-line samples of new novels (by the same authors, but unseen by the model).  From that short sample, the model is able to guess the correct author 83% of the time, and the correct author is one of the top two guesses 95% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train a Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we could use a pretrained set such as word2vec, but since I have a large data set, I've found using domain-specific training as shown here yields better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = './language_model/novels/'\n",
    "TRAIN_LANGUAGE_MODEL = 'train_language_model/'\n",
    "VAL_FOLDER = 'test/'\n",
    "\n",
    "TRAIN = f'{PATH}{TRAIN_LANGUAGE_MODEL}'\n",
    "VALIDATION = f'{PATH}{VAL_FOLDER}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The language model training folder contains text files of several books from Austen, Baum, Dickens, Fitzgerald, and Wodehouse. I use this to build a language model.  These files are taken directly from www.gutenberg.org (I removed the boiler plate Gutenberg intro and the license agreement at the end, but otherwise the text files are untouched.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful-damned.txt',\n",
       " 'bleak-house.txt',\n",
       " 'christmas-carol.txt',\n",
       " 'dorothy.txt',\n",
       " 'emma.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = !ls {TRAIN}\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An example excerpt from a novel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['immortality. Until the time came for this effort he would be Anthony',\n",
       " 'Patch--not a portrait of a man but a distinct and dynamic personality,',\n",
       " 'opinionated, contemptuous, functioning from within outward--a man who',\n",
       " 'was aware that there could be no honor and yet had honor, who knew the',\n",
       " 'sophistry of courage and yet was brave.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_lines = !cat {TRAIN}beautiful-damned.txt\n",
    "example_lines[20:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the Torchtext dataloader library, and set TEXT as a data.Field, using a spacy tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_break(x): return re.compile('<br />').sub(\"\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_english = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(x): return [tok.text for tok in spacy_english.tokenizer(substitute_break(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs=32        # batch size\n",
    "bptt=120     # number of words in each row of mini-batch (# words included in prediction of next word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer_function = partial(optim.Adam, betas=(0.7, 0.99))  # Optimizer will be Adam with slightly lowered momentum \n",
    "                                                             # (Default Adam momentum doesn't work well on RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FILES = dict(train=TRAIN_LANGUAGE_MODEL, validation=VAL_FOLDER, test=VAL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LanguageModelData comes from the fastai library. It loads the training and validation text files and creates a suitable RNN model.  Here we ignore words that don't appear at least 8 times in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save TEXT so that we'll make sure words map to the same IDs when we later create the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Exploring the language model data. Here are the: # training batches; # unique tokens in the vocab; # training sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738, 11858, 2838340)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train the Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " Here I use the fastai library to create a model based on the language model data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm feeding the model sequences of words from the training text, and then asking it to predict the next word. I don't expect it to get very good at this task (it's not surprising that the loss stays relatively high), but in the process of getting better at this, it has to develop good embeddings for the words. I'll later use these embeddings for my main goal (the author classification problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(optimizer_function, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d36f29bac0491789b03b5abbd1ff16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.186721   5.202713  \n",
      "    1      4.55629    4.625137                              \n",
      "    2      4.376035   4.504276                              \n",
      "    3      4.269179   4.362236                              \n",
      "    4      4.088331   4.226201                              \n",
      "    5      3.972325   4.17029                               \n",
      "    6      3.916161   4.160203                              \n",
      "    7      4.0351     4.174123                              \n",
      "    8      3.950396   4.131284                              \n",
      "    9      3.878697   4.113047                              \n",
      "    10     3.810488   4.096276                              \n",
      "    11     3.730453   4.080369                              \n",
      "    12     3.671942   4.086648                              \n",
      "    13     3.647436   4.087518                              \n",
      "    14     3.612968   4.083753                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0837526]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdeecc7d44e4d1fb9c2c2d1ab145c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.617367   4.084094  \n",
      "    1      3.644177   4.081234                              \n",
      "    2      3.616542   4.086579                              \n",
      "    3      3.609883   4.083892                              \n",
      "    4      3.617337   4.089175                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.089175]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-5, 1, wds=1e-6, cycle_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('novels_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load_encoder('novels_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test with Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here I take a look at the language model & check that it seems to have learned a decent sense of grammar and a reasonable word embedding.  I feed a \".\" as a primer, so that it'll likely start a new sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "starter_text=\"\"\". \"\"\"\n",
    "num_words = 200\n",
    "s = [spacy_tokenizer(starter_text)]\n",
    "t=TEXT.numericalize(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I feed this input to the model and ask it to generate 200 words (at each step, I feed in the text it has already generated).  I introduce \"beam\" and \"more_random\" to encourage a bit of variety in the generated text.  (Instead of always picking the most likely word, it can choose from the \"beam\" most likely words.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is just for formatting.  I undo some of the tokenization (for example turning can 't back into can't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The same, the way to the end of the night. I was not aware that I was going to make the thing a little more. I had been thinking that the thing would come out, but it seemed as if I had not been able. You're right, said mr. wooster, and I'll tell it, for I am sure I shall never have any idea of that. You are right. I said. I was not quite afraid. You are right. You are a man, my love. I do not think you will. I am sure I don't want to know what you mean. I'm not a-going on. I don't want to be a man, I suppose. But I am going to tell you, he said. I am going to the castle. I hadn't a word about him, and I had no doubt he would be so good as...\n"
     ]
    }
   ],
   "source": [
    "beam = 2\n",
    "more_random = True\n",
    "print_lead = \"\"\n",
    "cap = True\n",
    "skip_space = True\n",
    "\n",
    "print(print_lead, end = '')\n",
    "    \n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "res,*_ = m(t)\n",
    "m[0].bs=bs\n",
    "\n",
    "for i in range(num_words):\n",
    "    [ps, n] =res[-1].topk(beam)\n",
    "    if more_random or i<beam or i%4 == 0:\n",
    "        w = n[np.random.randint(0, beam)]\n",
    "    else:\n",
    "        w = n[0]\n",
    "    while w.data[0] == 0:\n",
    "        w = n[np.random.randint(0, beam)]\n",
    "    wstr = TEXT.vocab.itos[w.data[0]]\n",
    "    \n",
    "    # From here on, I could just print wstr, but instead I've added a bit of formatting to make the output look better.\n",
    "    # Mainly, I'm removing spaces, or capitalizing words after punctuation.\n",
    "    \n",
    "    if wstr=='i': wstr='I'\n",
    "    if wstr=='nt': wstr = 'not'\n",
    "    if cap:\n",
    "        wstr = wstr.capitalize()\n",
    "    if wstr in ['.', '?', '!', '“']: \n",
    "        cap=True\n",
    "    elif wstr not in ['”', '\"']:\n",
    "        cap=False\n",
    "    if skip_space or wstr in ['.', ',', ';', \"'\", '”', \"n't\", \"n’t\", \"’ll\", \"'ll\", \"’s\", \"’ve\", \"'ve\", \"’d\", \"’re\", \"’m\", \"'s\", \"'d\", \"?\", \"!\", \"'re\", \"'m\"]:\n",
    "        print(wstr, end='')\n",
    "        skip_space = False\n",
    "    elif wstr=='“':\n",
    "        print(f'\\n      {wstr}', end='')\n",
    "        skip_space = True\n",
    "    elif wstr in ['to-', '-', 'good-']:\n",
    "        print(wstr, end='')\n",
    "        skip_space = True\n",
    "    elif wstr=='\"':\n",
    "        pass\n",
    "    else:\n",
    "        print(f' {wstr}', end='')\n",
    "              \n",
    "    res,*_ = m(w[0].unsqueeze(0))\n",
    "\n",
    "print('...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use the word embeddings I've created to train a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the saved vocab from the language model, to ensure the same words map to the same IDs, if I've stepped away from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I build a dataset that will feed the model a line from a novel, with the author's name as the label.  Splits is used to create a training/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortAuthorsDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, path, text_field, label_field, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for label in ['Austen', 'Baum', 'Dickens', 'Fitzgerald', 'Wodehouse']:\n",
    "            for fname in glob(os.path.join(path, label, '*.txt')):\n",
    "                with open(fname, 'r') as f:\n",
    "                    for line in f:\n",
    "                        text = f.readline()\n",
    "                        if text!='\\n':\n",
    "                            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex): return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, root='.data',\n",
    "               train='train', test='test', **kwargs):\n",
    "        return super().splits(\n",
    "            root, text_field=text_field, label_field=label_field,\n",
    "            train=train, validation=None, test=test, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_LABEL = data.Field(sequential=False)\n",
    "short_splits = ShortAuthorsDataset.splits(TEXT, AUTHOR_LABEL, PATH, train='train', test='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69186, 16466)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_splits[0].examples), len(short_splits[1].examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I look at an example from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Austen',\n",
       " 'to the rank of a baronet ’s lady , with all the comforts and consequences')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = short_splits[0].examples[1]\n",
    "t.label, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, short_splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = md2.get_model(optimizer_function, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m2.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)      # add some regularization (to avoid overfitting)\n",
    "m2.load_encoder('novels_enc')                        # load the word vector model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.clip=25.\n",
    "lrs=np.array([1e-5, 1e-5, 1e-4, 1e-4, 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.freeze_to(-1)    # I expect my model is already decent, so I freeze most of the layers and finetune only the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eceddfe0631e4664b475d990c5bfed93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      1.165594   1.560178   0.364947  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5601777, 0.36494741101288103]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.fit(lrs, 1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train all the layers with a very small learning rate.  cycle_len is a great feature from the fastai library - it lowers the learning rate over the training epochs (with restarts at the start of each cycle) to achieve higher accuracy, without my needing to standby and babysit the learning rate manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0868421cc54f60ab372414542f801b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      1.119698   1.554734   0.360444  \n",
      "    1      1.137379   1.551771   0.366741                     \n",
      "    2      1.108979   1.544455   0.371595                     \n",
      "    3      1.108624   1.54133    0.368487                     \n",
      "    4      1.088771   1.550971   0.365831                     \n",
      "    5      1.08967    1.554331   0.379834                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5543311, 0.3798341424141115]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.fit(lrs/10, 3, metrics=[accuracy], cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38% accuracy is better than 1 in 5 chance, but it's not great. Next I'll try giving the model more than 1 line to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same but with longer text samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presumably the model will have an easier time if I give it slightly longer text samples from the novels. Now I feed it 6 lines at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAuthorsDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, path, text_field, label_field, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for label in ['Austen', 'Baum', 'Dickens', 'Fitzgerald', 'Wodehouse']:\n",
    "            for fname in glob(os.path.join(path, label, '*.txt')):\n",
    "                with open(fname, 'r') as f:\n",
    "                    for line in f:\n",
    "                        text = \"\"\n",
    "                        i=0\n",
    "                        while i<6:              # Add 6 lines to text\n",
    "                            t = f.readline()\n",
    "                            if t=='EOF':\n",
    "                                break\n",
    "                            if t!='\\n':         # Skip the line if it's blank\n",
    "                                text += t\n",
    "                                i+=1\n",
    "                        examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex): return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, root='.data',\n",
    "               train='train', test='test', **kwargs):\n",
    "        return super().splits(\n",
    "            root, text_field=text_field, label_field=label_field,\n",
    "            train=train, validation=None, test=test, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_LABEL = data.Field(sequential=False)\n",
    "long_splits = LongAuthorsDataset.splits(TEXT, AUTHOR_LABEL, PATH, train='train', test='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20504, 4919)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_splits[0].examples), len(long_splits[1].examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "md3 = TextData.from_splits(PATH, long_splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Austen',\n",
       " 'acquaintance as thought miss ward and miss frances quite as handsome as \\n miss maria , did not scruple to predict their marrying with almost equal \\n advantage . but there certainly are not so many men of large fortune in \\n the world as there are pretty women to deserve them . miss ward , at the \\n end of half a dozen years , found herself obliged to be attached to \\n the rev. mr. norris , a friend of her brother - in - law , with scarcely any')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = long_splits[0].examples[1]\n",
    "t.label, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I've tried some different values of dropout, and I kept the most successful set. It's worth exploring more \n",
    "hyperparameters here to get even better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = md3.get_model(optimizer_function, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl,     \n",
    "            dropout=.01, dropouti=.1, wdrop=.1, dropoute=.005, dropouth=.1)\n",
    "#            dropout=.2, dropouti=.5, wdrop=.6, dropoute=.1, dropouth=.5)\n",
    "#            dropout=.05, dropouti=.3, wdrop=.3, dropoute=.01, dropouth=.15)      \n",
    "#            dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3) \n",
    "\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)      # add some regularization (to avoid overfitting)\n",
    "m3.load_encoder('novels_enc')                        # load the word vector model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip=25.\n",
    "lrs=np.array([1e-4, 1e-4, 1e-3, 1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544fe33a13f64b39984a31efc521f93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.561768   0.88779    0.693235  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.88778967, 0.6932347544601986]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19631b836b640cfb34236e27279f04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.335311   0.781723   0.729152  \n",
      "    1      0.266786   0.638505   0.777403                    \n",
      "    2      0.230577   0.638205   0.785803                    \n",
      "    3      0.207183   0.613414   0.792014                    \n",
      "    4      0.210763   0.62506    0.787144                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6250605, 0.7871435629082965]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs/10, 1, metrics=[accuracy], cycle_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7e2bc203d841ddb157d4397601b105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.220866   1.142      0.7186    \n",
      "    1      0.118115   0.701368   0.823546                     \n",
      "    2      0.056187   0.7014     0.832069                     \n",
      "    3      0.035933   0.716181   0.830242                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7161807, 0.830242447651826]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "83% of the time, the model is successfully predicting the correct author, based on 6 lines of text of a novel it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I look more at the examples the model gets wrong.  Is the model's 2nd or 3rd guess correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m3.predict_with_targs()   # Make predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(preds, axis=1) == targs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her are the first 20 incorrect guesses. For each row, I list the model's top 3 guesses (in order), and then the correct answer.  Usually the correct answer is the 2nd guess, and occasionally the 3rd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3, 1, 4], 4),\n",
       " ([3, 1, 4], 4),\n",
       " ([1, 3, 5], 5),\n",
       " ([1, 3, 2], 3),\n",
       " ([3, 4, 1], 4),\n",
       " ([3, 1, 4], 1),\n",
       " ([3, 4, 2], 4),\n",
       " ([1, 3, 4], 3),\n",
       " ([3, 2, 1], 1),\n",
       " ([3, 2, 1], 2),\n",
       " ([1, 3, 2], 3),\n",
       " ([1, 3, 2], 3),\n",
       " ([1, 3, 2], 3),\n",
       " ([1, 3, 2], 3),\n",
       " ([1, 3, 5], 3),\n",
       " ([4, 3, 1], 3),\n",
       " ([1, 3, 2], 3),\n",
       " ([1, 3, 4], 3),\n",
       " ([1, 3, 5], 5),\n",
       " ([1, 3, 4], 4)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.argsort(-preds[~correct], axis=1)[:20, :3].tolist(), targs[~correct][:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that, I wonder how often is the correct author one of the model's top two guessess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_guesses = np.argsort(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_two = [ordered_guesses[i, 5] == targs[i] or ordered_guesses[i, 4] == targs[i] for i in range(len(targs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.sum(top_two)     # Number of times model was in the top two guesses\n",
    "total = len(top_two)       # Total number of validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4686, 4919, 0.9526326489123805)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, total, corr/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts the correct answer 83% of the time. The correct answer is one of the top two guesses 95.3% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
